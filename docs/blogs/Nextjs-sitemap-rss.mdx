---
title: Next.js에서 sitemap, rss 작성 방법
date: "2024-03-17"
description: 검색 기능 향상을 위한 과정
image: /posts/Nextjs-sitemap-rss/Thumbnail.png
tag: Next
---

저는 Next.js로 만들어진 블로그를 운영하고 있습니다.

블로그가 구글, 네이버 등 포털에서 검색되기 위해서는 서치 콘솔에 등록해야 한다는 것을 알게되었습니다.

- [Google Search Console](https://search.google.com/search-console)
- [네이버 서치어드바이저](https://searchadvisor.naver.com/)

서치 콘솔에 도메인을 등록하는 과정에서 sitemap과 rss 그리고 robots.txt가 있어야 원활하게 각 포털의 크롤러들이 제 블로그의 정보를 수집할 수 있음을 알았습니다.

그래서 Next.js에서 sitemap과 rss를 생성하는 법을 찾아보았지만 정보가 많이 없어서 글로 남깁니다.

## Sitemap 생성하기

> 사이트맵(sitemap)에는 우리의 블로그에서 페이지, 등록 일자와 같은 정보들이 적혀있습니다.

저는 블로그 포스팅을 하고 자동적으로 sitemap.xml 파일을 생성되도록 해놨습니다.

```tsx
// src/app/sitemap.xml
import posts from "@/utils/getPosts";
import { MetadataRoute } from "next";

const URL = "https://post.sid12g.dev";

export default function sitemap(): MetadataRoute.Sitemap {
  const postList = posts.map((postName) => ({
    name: postName.meta.title,
    slug: postName.slug,
    // content: postName.content,
    date: postName.meta.date,
  }));
  const postsRoute = postList.map(({ slug, date }) => {
    return {
      url: `${URL}/posts/${slug}`,
      lastModified: date,
    };
  });

  const routes = [""].map((route) => ({
    url: `${URL}${route}`,
    lastModified: new Date().toISOString(),
  }));

  return [...routes, ...postsRoute];
}
```

간단하게 코드를 설명한다면, posts의 경우 모든 포스트의 정보가 들어있는 변수입니다.

posts에서 각 포스트의 주소와, 날짜를 필터링 한 뒤, 포스트 수 만큼 이를 sitemap으로 만들어주는 것 입니다.

이는 도메인 뒤에 /sitemap.xml 을 붙여 확인하실 수 있습니다.

![PodfileCode](/posts/Nextjs-sitemap-rss/sitemap.png)

## Rss 생성하기

> rss란? 블로그처럼 컨텐츠 업데이트가 자주 일어나는 웹사이트에서, 업데이트된 정보를 쉽게 구독자들에게 제공하기 위해 XML을 기초로 만들어진 데이터 형식 입니다.

또한 구글서치콘솔에는 rss 파일 또한 등록해서 검색엔진에 도움을 줄 수 있습니다.

```tsx
// src/app/feed.xml/route.ts
import posts from "@/utils/getPosts";
import RSS from "rss";

async function getFeedData() {
  return posts;
}

export async function GET() {
  const feed = new RSS({
    title: "sid12g's blog",
    description: "조성민의 블로그에 오신 것을 환영합니다.",
    generator: "RSS for Node and Next.js",
    feed_url: "https://post.sid12g.dev/feed.xml",
    site_url: "https://post.sid12g.dev",
    image_url: "https://post.sid12g.dev/images/blog_image.png",
    copyright: `Copyright ${new Date().getFullYear().toString()}`,
    language: "ko-KR",
    pubDate: new Date().toUTCString(),
    ttl: 60,
  });

  const allPosts = await getFeedData();

  if (allPosts) {
    allPosts.map((post: any) => {
      feed.item({
        title: post.meta.title,
        description: post.meta.description,
        url: `https://post.sid12g.dev/posts/${post.slug}`,
        categories: [post.meta.tag],
        date: post.meta.date,
        custom_elements: [{ "content:encoded": post.content }],
      });
    });
  }

  return new Response(feed.xml({ indent: true }), {
    headers: {
      "Content-Type": "application/xml; charset=utf-8",
    },
  });
}
```

위 코드도 간단하게 설명한다면, 우선 feed에 사이트 기본 정보를 담은 후 모든 포스트의 정보가 있는 allPosts를 가져와서

각 포스트의 제목, 설명, 주소 등을 가져와 이를 rss로 만드는 것입니다.

이는 도메인 뒤에 /feed.xml 을 붙여 확인하실 수 있습니다.

![PodfileCode](/posts/Nextjs-sitemap-rss/rss.png)

## Robots.txt 작성하기

```text
// src/app/robots.txt

User-agent: Googlebot
Allow : /

User-agent: Yeti
Allow: /

User-agent: *
Disallow: /

Sitemap: https://post.sid12g.dev/sitemap.xml
```

robots.txt는 각 포털의 크롤러들이 수집할 수 있도록 권한을 주는 것입니다.

위 코드는 구글과 네이버의 크롤러만 수집할 수 있도록 설정한 상태입니다.

이는 도메인 뒤에 /robots.txt 을 붙여 확인하실 수 있습니다.

![PodfileCode](/posts/Nextjs-sitemap-rss/robots.png)

위와 같이 sitemap, rss, robots.txt를 사용한다면 여러분의 사이트의 노출에 더 좋은 영향을 끼칠 수 있을 것 입니다.

구글 서치 콘솔에 등록하면 검색 뿐 아니라 사이트의 유입 검색어, 통계, 순위 등 다양한 정보를 알 수 있으니 꼭 등록해보시길 바랍니다.

[이미지: freepik]
